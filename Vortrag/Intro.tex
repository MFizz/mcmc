

\subsection{Markov Chain Monte Carlo}
\begin{frame}
\frametitle{Markov Chain Monte Carlo}
\begin{block}{Why is it important}

\begin{itemize}

\item very powerful tool for sampling from/computing expectations with respect to very complicated high dimension probability functions
\item revolutionized statistical computing 
\item was named one of the top 10 most influential algorithms from the 20th century by CiSE
\end{itemize}
\end{block}
\end{frame}


\subsection{Why adaptive?}
\begin{frame}
\frametitle{Why adaptive?}
\begin{block}{Problems}
\begin{itemize}
\item tuning of associated parameters
\item optimizing performance
\end{itemize} 
\end{block}
\begin{block}{Solutions}
\begin{itemize}


\item "learning" parameters
\item adapting to theoretically "ideal" values 
\end{itemize}
\end{block}
\end{frame}


\subsection{Criteria}
\begin{frame}
\frametitle{Criteria}
\begin{block}{acceptance rate}
\begin{itemize}
  \item $\alpha = \frac{\# accepted}{\# samples}$
  \item $0.44$ for univariate distributions
  \item $0.234$ for $d\geq 5$ dimensions
\end{itemize}

\end{block}
\begin{block}{suboptimality}
\begin{itemize}
  \item $b = d\cdot \frac{\sum_{i=1}^d \lambda_i^{-2}}{(\sum_{i=1}^d
  \lambda_i^{-1})^2}$
  \item $\lambda_i$ are eigenvalues of $\Sigma_p^{0.5}\Sigma^{-0.5}$
  \item $\Sigma_p$ : proposal covariance matrix
  \item $\Sigma_p$ : target covariance matrix
  \item usually $b>1$, optimum at $b=1$
\end{itemize}

\end{block}
\end{frame}

\begin{frame}
\frametitle{Criteria}
\begin{block}{autocorrelation time}
\begin{itemize}
  \item $ACT = 1 + 2\sum_{i=1}^{\infty} autocorr(i)$
  \item $autocorr(k) = 1/((n-k)\cdot v)\cdot 
  \sum_{t=1}^{n-k}(x^t-\mu)(x^{t+k}-\mu)$
  \item the lower the better!
\end{itemize}

\end{block}
\begin{block}{average squared jump distance}
\begin{itemize}
  \item $ASJD = \sum_{k=1}^\infty \sqrt{\sum_{i=0}^d (x_{(i)}^k-x_{(i)}^{k+1})^2}$
  \item the higher the better!
\end{itemize}

\end{block}
\end{frame}